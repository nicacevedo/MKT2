Hour + Day + Week, #Fórmula
data = train, #Datos
method = "lm", #Algoritmo
na.action = na.pass, # Ignorar NA
trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold)
)
test.lm3  <- predict(train.lm3 , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.lm3 <- test$Rating-test.lm3 #Calcular los errores de predicción (dato real - dato estimado)
summary(train.lm3)
print(paste('Error de predicción: ', mean(abs(error.lm3))))
#Regresión autoselección
# Lasso
train.lasso <- train(form = Rating ~
Branch * `Customer type` * Month  +
Gender  * Payment * `Product line` +
Hour + Day + Week +
`Unit price`*Quantity, #Fórmula
data = train, #Datos
method = "glmnet", #Algoritmo
tuneGrid = expand.grid(alpha = 1, lambda = 1),
trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold)
)
test.lasso  <- predict(train.lasso , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.lasso <- test$Rating-test.lasso #Calcular los errores de predicción (dato real - dato estimado)
print(paste('Error de predicción: ', mean(abs(error.lasso))))
# Regresión NO-autoselección
# Ridge
train.rr <- train(form = Rating ~
Branch * `Customer type` * Month  +
Gender  * Payment * `Product line` +
Hour + Day + Week +
`Unit price`*Quantity, #Fórmula
data = train, #Datos
method = "glmnet", #Algoritmo
tuneGrid = expand.grid(alpha = 0, lambda = 1),
trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold)
)
test.rr <- predict(train.rr , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.rr <- test$Rating-test.rr #Calcular los errores de predicción (dato real - dato estimado)
print(paste('Error de predicción: ', mean(abs(error.rr))))
#Regresión autoselección
# stepwise backward
train.swb <- train(form = Rating ~
Branch * `Customer type` * Month  +
Gender  * Payment * `Product line` +
Hour + Day + Week +
`Unit price`*Quantity, #Fórmula
data = train, #Datos
method = "leapBackward", #Algoritmo
tuneGrid = data.frame(nvmax = 1:15),
trControl = trainControl(method = "cv", number = 5)#Method = cross validation, number=10 (k-fold)
)
test.swb <- predict(train.swb , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.swb <- test$Rating-test.swb #Calcular los errores de predicción (dato real - dato estimado)
print(paste('Error de predicción: ', mean(abs(error.swb))))}
#Regresión autoselección
# stepwise backward
train.swb <- train(form = Rating ~
Branch * `Customer type` * Month  +
Gender  * Payment * `Product line` +
Hour + Day + Week +
`Unit price`*Quantity, #Fórmula
data = train, #Datos
method = "leapBackward", #Algoritmo
tuneGrid = data.frame(nvmax = 1:15),
trControl = trainControl(method = "cv", number = 5)#Method = cross validation, number=10 (k-fold)
)
test.swb <- predict(train.swb , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.swb <- test$Rating-test.swb #Calcular los errores de predicción (dato real - dato estimado)
print(paste('Error de predicción: ', mean(abs(error.swb))))
#Regresión autoselección
# stepwise backward
train.swb <- train(form = Rating ~
Branch * `Customer type` * Month  +
Gender  * Payment * `Product line` +
Hour + Day + Week +
`Unit price`*Quantity, #Fórmula
data = train, #Datos
method = "leapBackward", #Algoritmo
tuneGrid = data.frame(nvmax = 1:15),
trControl = trainControl(method = "cv", number = 5)#Method = cross validation, number=10 (k-fold)
)
test.swb <- predict(train.swb , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.swb <- test$Rating-test.swb #Calcular los errores de predicción (dato real - dato estimado)
print(paste('Error de predicción: ', mean(abs(error.swb)))
#Regresión autoselección
# stepwise backward
train.swb <- train(form = Rating ~
Branch * `Customer type` * Month  +
Gender  * Payment * `Product line` +
Hour + Day + Week +
`Unit price`*Quantity, #Fórmula
data = train, #Datos
method = "leapBackward", #Algoritmo
tuneGrid = data.frame(nvmax = 1:15),
trControl = trainControl(method = "cv", number = 5)#Method = cross validation, number=10 (k-fold)
)
test.swb <- predict(train.swb , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.swb <- test$Rating-test.swb #Calcular los errores de predicción (dato real - dato estimado)
print(paste('Error de predicción: ', mean(abs(error.swb))))
rating.test <- data.frame(lm1=test.lm, lm2=test.lm2, lm3=test.lm3, lasso=test.lasso, ridge=test.rr, step.back=test.swb, rating=test$Rating)
error.test <- data.frame(lm1=error.lm, lm2=error.lm2, lm3=error.lm3, lasso=error.lasso, ridge=error.rr, step.back=error.swb)
summary(abs(error.test))
summary(error.test)
boxplot(abs(subset(error.test))); title(main="RL + Autom models", sub="Forecasting Absolute Errors")
boxplot(subset(error.test)); title(main="RL + Autom models", sub="Forecasting Errors")
# Min-Max:
min.max <- function(column){
max <- max(column)
min <- min(column)
norm.column <- (column-min)/(max-min)
return(norm.column)
}
# Copia de train y test
train.knn <- data.frame(train)
test.knn  <- data.frame(test)
# Unit Price
train.knn$Unit.price <- min.max(train$`Unit price`)
test.knn$Unit.price  <- min.max(test$`Unit price`)
# Quantity
train.knn$Quantity <- min.max(train$Quantity)
test.knn$Quantity  <- min.max(test$Quantity)
# Rating
#train.knn$Rating <- min.max(train$Rating)
#test.knn$Rating  <- min.max(test$Rating)
head(train.knn)
#Modelo de aprendizaje de máquinas
#1. ML --> KNN
train.knn.prediction<- train(Rating ~
Branch * Customer.type* Month  +
Gender  * Payment * Product.line +
Hour + Day + Week +
Unit.price*Quantity, #Fórmula
data=train.knn,
method="knn",
trControl = trainControl("cv", number=10),
preProcess = c("center","scale"),
tuneLength = 10
)
print(train.knn.prediction)
ggplot(train.knn.prediction)
test.knn.prediction  <- predict(train.knn.prediction, newdata=test.knn)
error.knn <- test.knn$Rating-test.knn.prediction
print(paste('Error de predicción: ', mean(abs(error.knn))))
#2. ML --> Random forest
train.randomf <- train(Rating ~
Branch * `Customer type` * Month  +
Gender  * Payment * `Product line` +
Hour + Day + Week +
`Unit price`*Quantity, #Fórmula
data=train, method="rf",
trControl = trainControl("cv", number=5),
preProcess = c("center","scale"),
tuneLength = 5
)
print(train.randomf)
ggplot(train.randomf)
test.randomf  <- predict(train.randomf, newdata=test)
error.randomf <- test$Rating-test.randomf
print(paste('Error de predicción: ', mean(abs(error.randomf))))
sqrt(9)
error.knn^2
mean(error.knn^2)
sqrt(mean(error.knn^2))
rmse(error.knn)
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
#Comparación modelos y recomendación
sqrt(mean(error.knn^2))
rmse(error.knn)
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = "1.741664"#knn
Metricas[7,2] = rmse(train$Rating,test.rf) #rf
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = "1.741664"#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = "1.482653" #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
sqrt(mean(error.x))
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = "1.741664"#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = "1.482653" #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = rmse(train.knn$Rating,test.knn.prediction)#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = "1.482653" #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = rmse(train.knn$Rating,test.knn.prediction)#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = mae(train.knn$Rating,test.knn.prediction) #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
print(paste('Error de predicción: ', mae(train$Rating,test.randomf)))
print(paste('Error de predicción: ', mae(train$Rating,test.knn.prediction)))
print(paste('Error de predicción: ', mae(train$Rating,test.swb)))
print(paste('Error de predicción: ', mae(train$Rating,test.rr)))
print(paste('Error de predicción: ', mae(train$Rating,lasso)))
print(paste('Error de predicción: ', mae(train$Rating,test.lasso)))
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = rmse(train.knn$Rating,test.knn.prediction)#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = mae(train.knn$Rating,test.knn.prediction) #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = rmse(train.knn$Rating,test.knn.prediction)#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = mae(train.knn$Rating,test.knn.prediction) #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
# Dataframe para Boxplots
rating.test <- data.frame(lm1=test.lm, lm2=test.lm2, lm3=test.lm3, lasso=test.lasso, ridge=test.rr, step.back=test.swb, knn=test.knn.prediction, rf=test.randomf, rating=test$Rating)
error.test <- data.frame(lm1=error.lm, lm2=error.lm2, lm3=error.lm3, lasso=error.lasso, ridge=error.rr, step.back=error.swb, knn=error.knn, rf=error.randomf)
boxplot(abs(subset(error.test))); title(main="RL + Autom models", sub="Forecasting Absolute Errors")
boxplot(subset(error.test)); title(main="RL + Autom models", sub="Forecasting Errors")
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = rmse(train.knn$Rating,test.knn.prediction)#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = mae(train.knn$Rating,test.knn.prediction) #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
# Dataframe para Boxplots
rating.test <- data.frame(lm1=test.lm, lm2=test.lm2, lm3=test.lm3, lasso=test.lasso, ridge=test.rr, step.back=test.swb, knn=test.knn.prediction, rf=test.randomf, rating=test$Rating)
error.test <- data.frame(lm1=error.lm, lm2=error.lm2, lm3=error.lm3, lasso=error.lasso, ridge=error.rr, step.back=error.swb, knn=error.knn, rf=error.randomf)
boxplot(abs(subset(error.test))); title(main="RL + Autom models", sub="Forecasting Absolute Errors")
boxplot(subset(error.test)); title(main="RL + Autom models", sub="Forecasting Errors")
#Comparación modelos y recomendación
library(Metrics) #paquete para funciones de métricas
Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","KNN","Random Forest"), RMSE=NA, MAE=NA)
#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = rmse(train.knn$Rating,test.knn.prediction)#knn
Metricas[7,2] = rmse(train$Rating,test.randomf) #rf
#MAPE
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,3] = mae(train.knn$Rating,test.knn.prediction) #knn
Metricas[7,3] = mae(train$Rating,test.randomf) #rf
kable(Metricas)
# Dataframe para Boxplots
rating.test <- data.frame(lm1=test.lm, lm2=test.lm2, lm3=test.lm3, lasso=test.lasso, ridge=test.rr, stepback=test.swb, knn=test.knn.prediction, rf=test.randomf, rating=test$Rating)
error.test <- data.frame(lm1=error.lm, lm2=error.lm2, lm3=error.lm3, lasso=error.lasso, ridge=error.rr, stepback=error.swb, knn=error.knn, rf=error.randomf)
boxplot(abs(subset(error.test))); title(main="RL + Autom models", sub="Forecasting Absolute Errors")
boxplot(subset(error.test)); title(main="RL + Autom models", sub="Forecasting Errors")
knitr::opts_chunk$set(echo = TRUE)
#Se limpia el espacio de trabajo
rm(list=ls())				# Limpiamos todos los objetos creados en R
graphics.off()	    # se limpian los graficos
#Se carga la base de datos
data("Fishing", package = "mlogit")
head(Fishing, 5)
table(mode)
table(mode)
table(mode)
#cargar libreria
library(mlogit)
#Formatear la data
Fishing2 <- mlogit.data(data = Fishing, shape = "wide", varying=2:9, choice = "mode")
# Veamos qué valores hay en la nueva
table(mode)
#cargar libreria
library(mlogit)
#Formatear la data
Fishing2 <- mlogit.data(data = Fishing, shape = "wide", varying=2:9, choice = "mode")
#cargar libreria
library(mlogit)
#Formatear la data
Fishing2 <- mlogit.data(data = Fishing, shape = "wide", varying=2:9, choice = "mode")
#La base ya viene en formato long, por lo que tiramos Logit condicionado
modelo_logit<-mlogit(mode ~ price + catch| income | 0 , data=Fishing2)
summary(modelo_logit)
#La base ya viene en formato long, por lo que tiramos Logit condicionado
modelo_logit<-mlogit(mode ~ 1 | income | 0 , data=Fishing2)
summary(modelo_logit)
#cargar libreria
library(mlogit)
#Formatear la data
Fishing2 <- mlogit.data(data = Fishing, shape = "wide", varying=2:9, choice = "mode")
#La base ya viene en formato long, por lo que tiramos Logit condicionado
modelo_logit<-mlogit(mode ~ 1 | income | 0 , data=Fishing2)
summary(modelo_logit)
#La base ya viene en formato long, por lo que tiramos Logit condicionado
modelo_logit<-mlogit(mode ~ 1 | income | 0 , data=Fishing2)
summary(modelo_logit)
#La base ya viene en formato long, por lo que tiramos Logit condicionado
modelo_logit<-mlogit(mode ~ 1 | income | 0 , data=Fishing2)
summary(modelo_logit)
#La base ya viene en formato long, por lo que tiramos Logit condicionado
modelo_logit<-mlogit(mode ~ 1 | income | 0 , data=Fishing2)
summary(modelo_logit)
#La base ya viene en formato long, por lo que tiramos Logit condicionado
modelo_logit<-mlogit(mode ~ price + catch| income | 0 , data=Fishing2)
summary(modelo_logit)
#Modelo probit
modelo_probit <- mlogit(mode ~ price | income | 0, data = Fishing2, probit = TRUE, print.level=1)
summary(modelo_probit)
#Modelo probit
modelo_probit <- mlogit(mode ~ price | income | 0, data = Fishing2, probit = TRUE)#, print.level=1)
#Modelo probit
modelo_probit <- mlogit(mode ~ price | income | 0, data = Fishing2, probit = TRUE)#, print.level=1)
summary(modelo_probit)
#Modelo probit
modelo_probit <- mlogit(mode ~ price | income | 0, data = Fishing2, probit = TRUE, print.level=1)
summary(modelo_probit)
#matriz var covar
vcov(modelo_probit)
#matriz var covar
vcov(modelo_probit)
#Modelo probit
modelo_probit <- mlogit(mode ~ price | income | 0, data = Fishing2, probit = TRUE)#, print.level=1)
summary(modelo_probit)
#matriz var covar
vcov(modelo_probit)
L1 <- matrix(0, 3, 3)
L1[! upper.tri(modelo_probit)] <- c(1, coef(modelo_probit)[6:10])
L1 <- matrix(0, 4, 4)
L1[! upper.tri(modelo_probit)] <- c(1, coef(modelo_probit)[6:10])
L1 <- matrix(0, 4, 4)
L1[! upper.tri(modelo_probit)] <- c(1, coef(modelo_probit)[2:9])
L1 <- matrix(0, 3, 3)
L1[! upper.tri(modelo_probit)] <- c(1, coef(modelo_probit)[8:12])
L1 <- matrix(0, 3, 3)
L1[! upper.tri(modelo_probit)] <- c(1, coef(modelo_probit)[8:12])
coef(modelo_probit)[8:12]
c(1, coef(modelo_probit)[8:12])
#c(1, coef(modelo_probit)[8:12])
L1[!upper.tri(modelo_probit)]
L1 <- matrix(0, 3, 3)
L1[!upper.tri(modelo_probit)] <- c(1, coef(modelo_probit)[8:12])
L1 <- matrix(0, 3, 3)
L1[!upper.tri(modelo_probit)] <- c(1, coef(modelo_probit)[8:12])
#c(1, coef(modelo_probit)[8:12])
L1[!upper.tri(modelo_probit)]
#c(1, coef(modelo_probit)[8:12])
#L1[!upper.tri(modelo_probit)]
L1 <- matrix(0, 3, 3)
L1
#c(1, coef(modelo_probit)[8:12])
#L1[!upper.tri(modelo_probit)]
L1 <- matrix(0, 3, 3)
L1[!upper.tri(L1)] <- c(1, coef(modelo_probit)[8:12])
#c(1, coef(modelo_probit)[8:12])
#L1[!upper.tri(modelo_probit)]
L1 <- matrix(0, 3, 3)
L1[!upper.tri(L1)] <- c(1, coef(modelo_probit)[8:12])
L1
#c(1, coef(modelo_probit)[8:12])
#L1[!upper.tri(modelo_probit)]
L1 <- matrix(0, 3, 3)
L1[!upper.tri(L1)] <- c(1, coef(modelo_probit)[8:12])
L1 %*% t(L1)
#matriz var covar
vcov(modelo_probit[8:12])
#matriz var covar
vcov(modelo_probit[8:12])
#matriz var covar
vcov(modelo_probit)
#matriz var covar
vcov(modelo_probit[8:12,])
#matriz var covar
modelo_probit
#matriz var covar
modelo_probit
#Modelo probit
modelo_probit <- mlogit(mode ~ price + catch | income | 0, data = Fishing2, probit = TRUE)#, print.level=1)
#Modelo probit
modelo_probit <- mlogit(mode ~ price | income | 0, data = Fishing2, probit = TRUE)#, print.level=1)
summary(modelo_probit)
#matriz var covar
#vcov(modelo_probit)
# Descomposición
L <- matrix(0, 3, 3)
L[!upper.tri(L)] <- c(1, coef(modelo_probit)[8:12])
#matriz var covar
V <- L %*% t(L)
V
M <- matrix(0, 3, 3)
#M[0,0] <- 0
M
M <- matrix(0, 3, 3)
M[,1] <- c(0 , 1, 0)
M[,2] <- c(-1,-1,-1)
M[,3] <- c(0 , 0, 1)
M
solve(M)
V_final = solve(M) %*% V %*% t(solve(M))
V_final
V_final = solve(M) %*% V %*% t(solve(M))
V_final
L
L = L + t(L)
L = L + t(L)
L
