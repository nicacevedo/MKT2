knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())				 #Limpia todos los objetos creados en R
graphics.off()			 #Limpia los gráficos
options(digits = 3)  #Dígitos después del punto para observar (décimas, centésimas,...)
set.seed(12345)      #Fijar semilla de aleatoriedad
setwd("C:/Users/color/Downloads/Marketing/LAB2_IN5602") #Fijar directorio de preferencia
# setwd("C:/Users/color/Downloads/Marketing/LAB2_IN5602") #Fijar directorio de preferencia
library(ggplot2)   #Para gráficos
library(readr)     #Para leer CSV
library(glmnet)    #Para ajustar modelo lineal
library(corrplot)  #Para realizar correlogramas
library(dplyr)     #Para manipulación de datos
library(ggplot2)   #Para gráficos
library(caret)     #Para validar y entrenar los modelos
library(knitr)
Casas <- read.csv("Casas.csv")
kable(Casas[1:5,1:9]) #kable crea una tabla head(Casas) sirve para visualiar la data
install.packages('rmarkdown')
kable(Casas[1:5,1:9]) #kable crea una tabla head(Casas) sirve para visualiar la data
# Anteponiendo el "-" escogemos las filas en de la base que no están en index
test  <- Casas[-index, ]
# Construimos un vector que esta formado por números de filas aleatoriamente
index <- sample(1:nrow(Casas), size= nrow(Casas)*0.7)
# Base de entrenamiento: del total de datos, tomamos las filas aletorizadas que tienen datos en index
train <- Casas[index, ]
# Anteponiendo el "-" escogemos las filas en de la base que no están en index
test  <- Casas[-index, ]
ggplot(data=Casas)+ #Se define un gráfico con ggplot()
aes(x=Sale_Price)+ #Solo le ingresamos el eje "x" para un histograma
geom_histogram(col="black", fill="green", alpha = 0.2) # Se define la forma del gráfico. "col" pinta el contorno, "fill" el entorno y "alpha" entrega transparencia
ggplot(data=Casas)+
aes(x=log(Sale_Price))+
geom_histogram(col="black", fill="green", alpha=0.2)+
xlab("Log(Precio de venta)")+ #Etiqueta para el eje x
ylab("Frecuencia")+ #Etiqueta para el eje y
ggtitle("Distribución log(Precio de venta)")+ #Título del gráfico
theme(plot.title = element_text(hjust = 0.5)) #centra el título en el gráfico. Lo ajusta en la posición horizontal (hjust = 0.5)
#R no siempre interpreta bien la naturaleza de las variables: Roof_Style y Heating_QC son factores, pero están como character(string)
#en train
train$Roof_Style=as.factor(train$Roof_Style)
train$Heating_QC=as.factor(train$Heating_QC)
#en test
test$Roof_Style=as.factor(test$Roof_Style)
test$Heating_QC=as.factor(test$Heating_QC)
library(gridExtra) #Para unir gráficas
g1 <- ggplot(Casas) +
aes(x=Year_Built, y=Sale_Price) +
geom_point(size=1, alpha=0.4) + #"size" aumenta el tamaño de los puntos, "alpha" da transparencia
geom_smooth(se=FALSE) + #Agregamos un ajuste no lineal sobre los puntos. "se" integra errores estándares
xlab("Año de construcción")
g2 <- ggplot(Casas) +
aes(x=Year_Built, y=Sale_Price) +
geom_point(size = 1, alpha = .4) +
geom_smooth(method = "lm", se = FALSE) + #Agregamos un ajuste lineal sobre los puntos.
scale_y_log10() + # "scale_y_log10" transforma el eje "y" a logaritmo.
xlab("Año de construcción")
grid.arrange(g1, g2, nrow = 1) #une las  gráficas.
ggplot(Casas) +
aes(x=Gr_Liv_Area, y=Sale_Price, col=Heating_QC)+ #Se agrega una dimensión de colores "col".
geom_point(size=1, alpha=0.4) +
geom_smooth(se=FALSE, method="lm") +
xlab("Espacio habitable")
ggplot(Casas) +
aes(x=Roof_Style, y=log(Sale_Price)) +
geom_boxplot(alpha=0.4, fill="black") #cambiamos el tipo de gráfico
train.lm <- train(form = Sale_Price ~ Year_Built+Gr_Liv_Area+Roof_Style+Heating_QC, #Fórmula
data = train, #Datos
method = "lm", #Algoritmo
trControl = trainControl(method = "cv", number = 10) #Method = cross validation, number=10 (k-fold)
)
test.lm  <- predict(train.lm , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.lm <- test$Sale_Price-test.lm #Calcular los errores de predicción (dato real - dato estimado)
#Ejecutar MARS (Multivariate adaptive regression spline)
train.mars <- train(form = Sale_Price ~ Year_Built+Gr_Liv_Area+Roof_Style+Heating_QC,
data=train,
method="earth", #MARS
trControl = trainControl("cv", number=10),
preProcess = c("center","scale"), #Pre-procesa datos. "center" resta el promedio de las variables, "scale" las divide por la desviación estandar. Esto ayuda para el tratamiento de outliers.
tuneLength = 5 #Indica que pruebe diferentes valores por default para el parámetro principal
)
print(train.mars)
ggplot(train.mars)
test.mars  <- predict(train.mars, newdata=test) #Vector de datos predichos
error.mars <- test$Sale_Price-test.mars #(dato real - dato estimado)
### Ejecutar KNN
train.knn <- train(Sale_Price ~ Year_Built+Gr_Liv_Area+Roof_Style+Heating_QC,
data=train, method="knn",
trControl = trainControl("cv", number=10),
preProcess = c("center","scale"),
tuneLength = 5
)
print(train.knn)
ggplot(train.knn)
test.knn  <- predict(train.knn, newdata=test)
error.knn <- test$Sale_Price-test.knn
### Ejecutar CART (Classification and Regression Trees)
train.cart <- train(Sale_Price ~ Year_Built+Gr_Liv_Area+Roof_Style+Heating_QC,
data=train, method="rpart2",
trControl = trainControl("cv", number=10),
preProcess = c("center","scale"),
tuneLength = 5
)
print(train.cart)
ggplot(train.cart)
test.cart  <- predict(train.cart, newdata=test)
error.cart <- test$Sale_Price-test.cart
### Ejecutar Random Forest
train.randomf <- train(Sale_Price ~ Year_Built+Gr_Liv_Area+Roof_Style+Heating_QC,
data=train, method="rf",
trControl = trainControl("cv", number=10),
preProcess = c("center","scale"),
tuneLength = 5
)
print(train.randomf)
ggplot(train.randomf)
test.randomf  <- predict(train.randomf, newdata=test)
error.randomf <- test$Sale_Price-test.randomf
sales.test <- data.frame(lm=test.lm, mars=unname(test.mars),  knn=test.knn,  cart=test.cart,  rf=test.randomf, sales=test$Sale_Price)
error.test <- data.frame(lm=error.lm, mars=unname(error.mars), knn=error.knn, cart=error.cart, rf=error.randomf)
summary(abs(error.test))
summary(error.test)
boxplot(abs(subset(error.test, select=-lm))); title(main="ML models", sub="Forecasting Absolute Errors")
boxplot(subset(error.test, select=-lm)); title(main="ML models", sub="Forecasting Errors")
