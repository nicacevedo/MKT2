---
title: 'Lab 4: Otros modelos de clasificación - Otoño 2021'
author: "Renato Ignacio Cerda Hernández"
date: "23/6/2021"
output:
  html_document:
    df_print: paged
    theme: simplex
    highlight: tango
    toc: yes
encoding: UTF-8
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Machine Learning

Machine Learning es un conjunto de métodos que Automatizar la construcción de modelos analíticos y se basa en la idea de que los sistemas pueden aprender de los datos, identificar patrones y tomar decisiones con una mínima intervención humana.

Los problemas más típicos que resuelven los modelos de Machine Learning son 2:

1. Regresiones: Predicción de una variable continua
2. Clasificación: Predeción de una variable discreta

# Laboratorio {.tabset}

## El Dataset

Trabajaremos con una base de datos que contiene los resultados de un análisis químico de vinos cultivados en Italia. Tres diferentes tipos de vino están representados en las 178 muestras, con los resultados de 13 análisis químicos registrados para cada muestra. La variable 'Type' corresponde a la variable categórica.

Los datos no contienen valores perdidos y se componen de solo datos numéricos, con la variable objetivo de tres clases 'Type' para la clasificación.

A continuación un diccionario de las variables:

* **Type** : Tipo de vino (factor)
* **Alcohol** : Alcohol (numérica)
* **Malic**: Ácido málico (numérica)
* **Ash**: Ceniza (numérica)
* **Alcalinity**: Alcalinidad de la ceniza (numérica)
* **Magnesium**: Magnesio (numérica)
* **Phenols**: Fenoles totales (numérica)
* **Flavanoids**: Flavonoides (numérica)
* **Nonflavanoids**: Fenoles no flavonoides (numérica)
* **Proanthocyanins** : Proantocianinas (numérica)
* **Color**: Intensidad del color (numérica)
* **Hue**: Matiz (numérica)
* **Dilution**: D280 / OD315 de vinos diluidos (numérica)
* **Proline**: Prolina (numérica)

```{r someVar, echo=FALSE, results="hide",include=FALSE}
library(caret) #librería modelos de ML
library(dplyr) #librería para usar antijoint y crear test data
library("rattle") #librería que contiene la BD wine
library('ggplot2')
library('MLmetrics')
rm(list=ls())   # Limpiamos todos los objetos creados en R. la función ls() indica los nombres de todos los objetos y rm() los remueve.
graphics.off()  # Limpiamos los gráficos en el ambiente Plots (esquina inferior derecha)
set.seed(12345) #Fijamos una semilla de aleatoriedad. Se debe realizar si se toman muestras aleatorias o se generan datos aleatorios. 
#install.packages('rattle')

wine=wine #agregamos la data al workspace
wine$Type=as.numeric(wine$Type) #convertimos a numerica la columna de tipo de vino para posteriormente convertirla a character
```

Head del dataset:
```{r}
head(wine[sample(nrow(wine),6 ), ])
```

## EDA

Para usar modelos de ML para clasificar es necesario que las categorías estén como texto:
```{r, echo=FALSE}
#character variable Type
wine$Type[wine$Type== 1] <- 'Tipo1'
wine$Type[wine$Type== 2] <- 'Tipo2'
wine$Type[wine$Type== 3] <- 'Tipo3'
```

Vemos la distribución de los tipos de vino en el dataset:
```{r}
ggplot(wine, aes(Type, fill=Type)) + geom_bar(alpha=0.8) +
  labs(x="Tipo", y="Número de Vinos en categoría") +
  guides(fill=FALSE)+ggtitle("Frecuencia de tipo de vinos")
```
```{r}
ggplot(wine, aes(x=Type,y=Alcohol,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Grado Alcohólico")+ggtitle("Boxplot de niveles de alcohol por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Malic,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Malic")+ggtitle("Boxplot de Malic por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Ash,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Ash")+ggtitle("Boxplot de Ash por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(Alcalinity, fill=Type)) + 
  geom_histogram(binwidth=1,alpha=0.8) +
  labs(fill="Tipo", x="Grados de alcohol", y="Número de vinos")+ggtitle("Frecuencia de Alcalinidad por tipo de vino")
```
```{r}
ggplot(wine, aes(x=Type,y=Magnesium,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Magnesium")+ggtitle("Boxplot de Magnesium por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Phenols,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Phenols")+ggtitle("Boxplot de Phenols por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Flavanoids,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Flavanoids")+ggtitle("Boxplot de Flavanoids por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Nonflavanoids,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Flavanoids")+ggtitle("Boxplot de Flavanoids por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Proanthocyanins,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Flavanoids")+ggtitle("Boxplot de Flavanoids por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(Color, fill=Type)) + 
  geom_histogram(binwidth=1,alpha=0.8) +
  labs(fill="Tipo", x="Intensidad del color", y="Número de vinos")+ggtitle("Frecuencia de Color por tipo de vino")
```
```{r}
ggplot(wine, aes(x=Type,y=Hue,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Hue")+ggtitle("Boxplot de Hue por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Dilution,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Hue")+ggtitle("Boxplot de Hue por tipo de vino")+guides(fill=FALSE)
```
```{r}
ggplot(wine, aes(x=Type,y=Proline,fill=Type)) + 
  geom_boxplot(alpha=0.8) +
  labs(fill="Tipo", x="Tipo de vino", y="Proline")+ggtitle("Boxplot de Proline por tipo de vino")+guides(fill=FALSE)
```

## KNN

### K-Nearest Neighbors

<img src="https://helloacm.com/wp-content/uploads/2016/03/2012-10-26-knn-concept.png" alt="KNN">
```{r}
trainwine=wine[sample(nrow(wine),100 ), ]
testwine=anti_join(wine, trainwine)

  
train.knn <- train( Type ~.,data=trainwine, method="knn",
                   trControl  = trainControl("cv",number=5,classProbs=TRUE, summaryFunction=multiClassSummary),
                   preProcess = c("center","scale"),
                   tuneLength = 6,
                   metric = 'logLoss')

print(train.knn)

ggplot(train.knn)

train.knn$results


test.knn<-predict(train.knn,newdata=testwine)
confusionMatrix(as.factor(test.knn),as.factor(testwine$Type))

Metrica=c('Precision','Recall','F1_Score', 'Accuracy')
Valores=c(Precision(testwine$Type,test.knn),Recall(testwine$Type,test.knn),F1_Score(testwine$Type,test.knn),Accuracy(testwine$Type,test.knn))
KNN=data.frame(Metrica,Valores)
#print(KNN)
head(KNN)
```

## Random Forest

### Random Forest

<img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/rfc_vs_dt1.png" alt="RF ">

```{r}
train.rf <- train( Type ~.,data=trainwine, method="rf",
                   trControl  = trainControl("cv",number=5,classProbs=TRUE, summaryFunction=multiClassSummary),
                   preProcess = c("center","scale"),
                   tuneLength = 6,
                   metric= 'logLoss')

print(train.rf)

ggplot(train.rf)

train.rf$results


test.rf<-predict(train.rf,newdata=testwine)
confusionMatrix(as.factor(test.rf),as.factor(testwine$Type))

Metrica=c('Precision','Recall','F1_Score', 'Accuracy')
Valores=c(Precision(testwine$Type,test.rf),Recall(testwine$Type,test.rf),F1_Score(testwine$Type,test.rf),Accuracy(testwine$Type,test.rf))
rf=data.frame(Metrica,Valores)
#print(rf)
head(rf)
```

## SVM

### Suppot Vector Machines

<img src="https://static.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm.png" alt="RF ">

```{r}
train.svm <- train( Type ~.,data=trainwine, method="svmLinear2",
                   trControl  = trainControl("cv",number=5,classProbs=TRUE, summaryFunction=multiClassSummary),
                   preProcess = c("center","scale"),
                   tuneLength = 6,
                   metric= 'logLoss')

print(train.svm)

ggplot(train.svm)

train.svm$results


test.svm<-predict(train.svm,newdata=testwine)
confusionMatrix(as.factor(test.svm),as.factor(testwine$Type))

Metrica=c('Precision','Recall','F1_Score', 'Accuracy')
Valores=c(Precision(testwine$Type,test.svm),Recall(testwine$Type,test.svm),F1_Score(testwine$Type,test.svm),Accuracy(testwine$Type,test.svm))
svm=data.frame(Metrica,Valores)
#print(svm)
head(svm)
```

## Métricas

### Métricas en modelos de clasificación

* *Accuracy* Indica sobre el total de elementos cuantos son predichos correctamente

$$Accuracy=\frac{TruePositives+TrueNegatives}{TruePositives+FalsePositives+TrueNegatives+FalseNegatives}$$

* *Precision* Indica respecto a los elementos predichos como positivos cuantos lo son efectivamente. 

$$Precision=\frac{TruePositives}{TruePositives+FalsePositives}$$

* *Recall - Sensibility* Mide respecto a todos los elementos que efectivamente son positivos cuantos fueron predichos correctamente. (Exhaustividad )

$$Recall=\frac{TruePositives}{TruePositives+FalseNegatives}$$

* *F1-Score* Entrega un promedio ponderado entre precision y recall.

$$F1_{score}=\frac{2⋅Recall⋅Precision}{Recall+Presicion}$$

## Preguntas

##### Pregunta 1

```{r p1}
# Seleccione 3 variables del dataset para generar las predicciones y argumente por qué serían buenas variables para predecir el tipo de vino. Puede realizar un EDA o basarse en los gráficos ya incluidos.
# Determine 2 métricas para comparar los modelos, justifique su elección.
# Si se viera en la obligación de NO agregar ciertas variables del dataset, comente sobre cuál o cuáles serían apoyándose en un EDA o los gráficos ya incluídos (Mínimo una variable)
```


##### Pregunta 2

```{r p2}
# Corra 2 modelos de clasificación con las variables seleccionadas anteriormente para predecir el tipo de vino.
# Cálcule para cada modelo las metricas seleccionadas para el set de testeo, además muestre la matriz de confusión.
# Comente sobre los resultados, ¿Los modelos poseen capacidad de generalización? ¿se observa overfitting o underfitting?


```

##### Pregunta 3


```{r p3}
# Compare los modelos a través de métricas presentadas en el laboratorio. ¿Con que modelo se quedaría? 


```

