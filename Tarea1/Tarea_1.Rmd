::: {style="text-align: right"}
**Universidad de Chile**
:::

::: {style="text-align: right"}
**Ingeniería Industrial**
:::

::: {style="text-align: right"}
**IN5602**: Marketing II
:::

::: {style="text-align: right"}
**Prof**: Marcel Goic
:::

::: {style="text-align: right"}
**Auxs**: R. Cerda, JP. Coddou, G.Mora, F. Moraga, A .Muñoz
:::

---
title:  'Tarea 1 - Semestre Otoño 2021'
author: 'Nicolás Acevedo, Constanza Bastías, Pablo Ubilla'
date:   '12 de mayo de 2021'
output:
  html_document:
    df_print: paged
    theme: simplex
    highlight: tango
    toc: no
encoding: UTF-8
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#  {.tabset}

## Enunciado

El canal moderno de supermercados ha crecido sostenidamente en todo el mundo y especialmente en los países en desarrollo. En esta tarea exploraremos el comportamiento de compras en una cadena de supermercados en Asia. Para estos efectos, "Supermerca2" ha provisto con información de ventas para tres de sus sucursales (A), (B) y (C) las cuales tienen sedes en las ciudades de Yangon, Mandalay y Naypyidaw respectivamente, en el lejano país de Birmania. "Supermerca2" vende productos de todo tipo, desde accesorios de moda hasta artículos de hogar y estilo de vida. Adicionalmente, la cadena posee un club de lealtad en que los clientes frecuentes pueden registrar sus compras al momento de la compra y así acceder a beneficios posteriormente.

Entre otras preguntas, "Supermerca2" está interesado en entender la satisfacción de sus clientes y así poder decidir sobre qué clientes enfocar los esfuerzos de ventas. En particular, en esta tarea nos concentraremos en entender qué factores afectan el Rating de un cliente, que corresponde a un puntaje en una escala de 10 puntos que indica el grado de satisfacción en la experiencia de compra. El estudio de la satisfacción de los clientes es relevante ya que por un lado nos permite identificar si ciertas salas del supermercado podrían estar entregando un servicio insatisfactorio y por otro nos entrega una señal temprana para saber la probabilidad de que un cliente haga una compra a futuro. En este sentido, la evaluación de la calidad de servicio podría ser informativa respecto al comportamiento de compra futuro.

Para el análisis dispone de una base de datos con una muestra de 1000 compras. El conjunto de datos es uno de los históricos de ventas de la empresa en donde se han registrado IDs de diferentes facturas en sus 3 sucursales durante las horas del día en que atienden. Además, se tienen registros del género del cliente, el precio y la cantidad del producto comprado, la forma de pago, entre otras.

La base de datos está disponible en <https://www.kaggle.com/aungpyaeap/supermarket-sales>, donde además puede acceder a un diccionario de datos con una descripción de cada una de las variables disponibles en la base de datos.

#### **Preguntas**

1.  (0 puntos) Explore los datos para entender la satisfacción de los clientes y qué variables podrían ayudar a predecir cuando un cliente está más satisfecho.

2.  (2.0 puntos) Usando los aprendizajes derivados de la exploración de datos, use un enfoque de regresión lineal para examinar cuantitativamente qué factores determinan la satisfacción al momento de realizar una compra.

-   

    a)  Proponga al menos dos especificaciones alternativas para el objetivo propuesto. Justifique muy brevemente por que las variables que está incluyendo en el modelo tienen sentido desde el punto de vista del negocio. Justifique además el nivel de agregación escogido y los índices considerados en el modelo.

-   

    b)  Sobre los dos modelos planteados en la parte anterior, aplique un método de selección automática de variables y compare respecto a los resultados anteriores.

3.  (1.0 puntos) Use al menos dos de los modelos de aprendizaje de máquinas que vimos en clases (MARS, kNN, regression tree, random forest) para generar un pronóstico de Rating de un cliente al realizar una compra y compare la capacidad de estos modelos con respecto a los de regresión lineal.

4.  (0.5 puntos) Compare las fortalezas y debilidades de los modelos anteriores, evalúe de acuerdo a algunas de las métricas que vimos en clases y discuta qué modelo recomendaría usar.

5.  (2.0 puntos) En esta parte, se compararán los grados de satisfacción entre las distintas salas de la cadena de supermercados. Para lo siguiente usted deberá clasificar cada evaluación de la calidad de servicios de acuerdo a si el cliente está o no satisfecho. Para eso puede considerar que un cliente está satisfecho si tiene un Rating mayor o igual a los 7 puntos. Con esto:

-   

    a)  Estimar un modelo de decisión homogéneo para cada sucursal y compare sus resultados entre sucursales. Discuta brevemente sus resultados.

-   

    b)  Estimar un modelo de decisión heterogéneo para cada sucursal y compare sus resultados entre sucursales. Discuta brevemente sus resultados.

-   *Observación: Recuerde que la variable utilizada es entera.*

6.  (0.5 puntos) Resuma sus aprendizajes principales en un máximo de 4 tablas o figuras. Redacte de manera concisa sus resultados tal como los reportaría al departamento comercial interesado en aprender del comportamiento de clientes. Agregue cualquier conclusión o idea que le parezca relevante de comunicar.

#### **Reglas del juego**

-   Las tareas buscan replicar parcialmente las labores a las que se enfrentarían en el análisis de datos en una organización para el apoyo en la toma de decisiones. Por esto, se han propuesto preguntas relativamente abiertas que requieren que ustedes discutan y decidan cual es el mejor enfoque de solución. Les pedimos que se involucren tempranamente en el desarrollo de la tarea para tener una discusión enriquecedora.

-   Todas las dudas, comentarios y errores publicarlos exclusivamente en el foro de u-cursos. De esta forma todos se benefician de las respuestas ofrecidas.

-   Consideramos que es muy importante que logren escribir un informe conciso con una redacción acorde de un informe técnico profesional, los análisis y las conclusiones que obtengan de cada pregunta es en específico lo que debe declararse. La presentación y comunicación de resultados es parte integral de la tarea y por tanto será evaluada cuidadosamente.

-   La tarea se desarrolla en grupos de máximo 3 integrantes. No hay excepciones. El entregable principal es un único markdown separado en tres tabs (a través de la opción .tabset). En el primer tab incluya todo el desarrollo de la tarea adecuadamente comentado. El segundo tab incluya el resumen de sus resultado de acuerdo a lo pedido en la pregunta 6. Este segundo tab es el que usarán en caso de que les corresponda presentar sus resultados. Considere el tercer tab como de anexos y puede incluir aquí cualquier resultado complementario. Para entregar sus resultados suba vía u-cursos un único archivo comprimido llamado t1-A1-A2-A3.zip, donde A1, A2 y A3 es el primer apellido de los integrantes del grupo. Incluya tanto el archivo .html de salida del markdown como los códigos fuentes que permitan reproducir sus resultados.

-   Para la pregunta 6 consideramos que 4 figuras son suficientes para resumir los aprendizajes más relevantes, pero si están convencidos de que agregar una figura adicional es absolutamente necesaria, ¡adelante!

-   La fecha de entrega de la tarea es el día miércoles 5 de Mayo a las 09:00 hrs, sin excepciones y no habrá plazo extra para la entrega. Si por algún motivo de fuerza mayor se ve imposibilitado de entregar la tarea en el plazo estipulado, deberá escribir directamente al profesor explicando su situación. El profesor decidirá el curso de acción de acuerdo a los méritos del caso.

-   Recuerde que tenemos contempladas dos sesiones de presentaciones de las tareas. La primera sesión, a realizarse el día jueves 29 de Abril, está destinada a que compartan sus avances y podamos identificar de manera conjunta cuáles podrían ser dificultades técnicas que requieran orientación adicional. La segunda sesión, a realizarse el día jueves 6 de Mayo, está destinada para que expongan los resultados más relevantes de su trabajo y resuman sus principales aprendizajes, para que tanto los compañeros como el equipo docente puedan proveer retroalimentación. Todos los grupos deben estar disponibles para presentar en ambas ocasiones, pero si hay grupos voluntarios se les dará preferencia. Las presentaciones tendrán una duración máxima de 10 minutos y no es necesario que preparen material adicional. Esperamos que la salida del markdown sea lo suficientemente explicativa para comunicar sus resultados.

-   El equipo docente considera que la copia de tareas atenta en contra de tu aprendizaje y por tanto aplicará todas las medidas que estén a su disposición para desincentivar esta mala práctica.

## Preliminares

Escribe acá todos los comandos que necesitas ejecutar antes de abordar las preguntas de la tarea (carga de librerías, lectura de datos, limpieza de la data, transformación de variables y todo lo que necesites)

#### Preparación Tarea

1.  Se cargan las librerías a utilizar, y se prepara el ambiente de R

```{r echo=FALSE}
rm(list=ls())   # Limpiamos todos los objetos creados en R.
graphics.off() # Limpiamos los gráficos en el ambiente Plots 
set.seed(12345) #Fijamos una semilla de aleatoriedad. 

# Cargamos librerias útiles
library(dplyr)
library(knitr) 
library(readr)
library(lubridate)
library(ggplot2)
library(lattice) 
library(caret) 
library(Hmisc)
library(Metrics) #paquete para funciones de métricas
```

2.  Se transformar las variables necesarias

```{r echo=FALSE}
# Cargar Bases de Datos
supermarket_sales <- read_csv("./supermarket_sales.csv")
df <- supermarket_sales

# Transformar a categoricas
df$Branch = as.factor(df$Branch)
df$City = as.factor(df$City)
df$`Customer type`= as.factor(df$`Customer type`)
df$Gender =as.factor(df$Gender)
df$`Product line` = as.factor(df$`Product line`)
df$Payment = as.factor(df$Payment)

# Pasar Date a tipo fecha
df$Date = as.Date(df$Date, tryFormats = c("%m/%d/%Y"))

# Obtenemos las horas de cada Time
df$Hour <- as.numeric(hour(df$Time))

# Obtenemos cada mes (como factor)
df$Month <- as.factor(month(df$Date))

# Agregamos el día de la semana (ordenados)
df$Day <- factor(weekdays(df$Date))

# Fracciones del día en mañana/almuerzo/tarde/noche
df$Frac_Day = as.factor(ifelse(df$Hour <= 11,1, ifelse(df$Hour<=15,2,ifelse(df$Hour<=17,3,4))))

# Devolvemos a factor las horas (esto pues para el paso anterior se necesitaban en numeric)
df$Hour <- as.factor(hour(df$Time))

# Creamos semanas de 7 días (cada mes con 4 semanas)
df$Week <- as.factor(ceiling(day(df$Date)/7))
df[df$Week == 5,'Week'] <- '4'

# Dividimos por semana (se cuentan las semanas de la primera fecha de la BD a la última)
df$Semana <- cut(df$Date, breaks = "1 week", labels = FALSE)
df$Semana = as.factor(df$Semana)
df <- df[with(df, order(df$Date)), ] 

```

3.  Se divide la base de datos en entrenamiento (train) y testeo (test) utilizando 80/20%

```{r echo=FALSE}
#Divsion de los datos

# samples aleatorio
index <- sample(1:nrow(df), size= nrow(df)*0.8)
# entrenamiento 80%
train <- df[index, ]
# test 20%
test  <- df[-index, ]

```

## Desarrollo

Documenta acá el desarrollo de tu tarea por pregunta.

#### Pregunta 1

(0 puntos) Explore los datos para entender la satisfacción de los clientes y qué variables podrían ayudar a predecir cuando un cliente está más satisfecho.

A continuación se realizan distitnos EDA, el primero sólo viendo cómo se comportan los datos de la base de datos (df), el segundo (bidimensional) se ve la relación entre las variables dadas , y los siguientes interaccionando variables, o bien con las creadas en la parte anterior.

##### 1. Exploración de datos

En primera instancia, se debe notar que hay ciertas variables en la base de datos que son redundantes o que no aportan nada de información en cuanto a la variabilidad de la variable de interés, como lo es caso de:

-   `City`: Aporta la misma información que `Branch`, por lo que es redundante (sólo 1 tienda por ciudad).

-   `Gross margin percentage`: Se mantiene constante también en toda la base.

-   `Total`: Se define como `Unit price`\*`Quantity`(1+0.05) = `Total`, por lo que es es reduante una vez que tenemos la información de las otras dos (sin tomar en cuenta la que es constante, ya que es sólo un ponderador fijo).

-   `Cogs`: Se define casi de manera idéntica a `Total`, ya que tiene los mismos valores que `Unit price`\*`Quantity`, por lo que también es redundante.

-   `Tax`: Es una proporción (5%) de las variables de precio y cantidad nuevamente, por lo que es redundante.

-   `Gross income`: Es idéntico a `Tax`; es reduntante.

Con respecto al resto de los atributos/variables (estime conveniente el nombre a su gusto o juicios) en la base, se revisa si existe alguna relación entre las distribuciones de las variables numéricas de la base de datos, para detectar tanto anomalías en estas o algún otro factor que se pueda observar de esta manera. De forma adicional, se realiza una transformación logarítmica de la variable `Unit price` para ver si se obtiene algo:

```{r P1}
#Exploración de datos

#1. Histograma variable de interes
ggplot(data=df)+ #Se define un gráfico con ggplot()
  aes(x=Rating)+ #Solo le ingresamos el eje "x" para un histograma
  geom_histogram(col="black", fill="green", alpha = 0.2)+ # Se define la forma del gráfico. "col" pinta el contorno, "fill" el entorno y "alpha" entrega transparencia
  ggtitle("Distribución de Rating") +#Título del gráfico
  theme(plot.title = element_text(hjust = 0.5))

#2. Histograma Unit price
ggplot(data=df)+
  aes(x=Total)+
  geom_histogram(col="black", fill="green", alpha=0.2)+
  xlab("Precio unitario")+ #Etiqueta para el eje x
  ylab("Frecuencia")+ #Etiqueta para el eje y
  ggtitle("Distribución Precio unitario")+ #Título del gráfico
  theme(plot.title = element_text(hjust = 0.5)) #centra el título en el gráfico. Lo ajusta en la posición horizontal (hjust = 0.5)

#3. Histograma Unit price usando log()
ggplot(data=df)+
  aes(x=log(Total))+
  geom_histogram(col="black", fill="green", alpha=0.2)+
  xlab("log(Precio unitario)")+ #Etiqueta para el eje x
  ylab("Frecuencia")+ #Etiqueta para el eje y
  ggtitle("Distribución Precio unitario Logarítmico")+ #Título del gráfico
  theme(plot.title = element_text(hjust = 0.5)) #centra el título en el gráfico. Lo ajusta en la posición horizontal (hjust = 0.5)

#4. Histograma de Quantity
ggplot(data=df)+
  aes(x=Quantity)+
  geom_histogram(col="black", fill="green", alpha=0.2)+
  xlab("Quantity")+ #Etiqueta para el eje x
  ylab("Frecuencia")+ #Etiqueta para el eje y
  ggtitle("Distribución Quantity")+ #Título del gráfico
  theme(plot.title = element_text(hjust = 0.5)) #centra el título en el gráfico. Lo ajusta en la posición horizontal (hjust = 0.5)

```

Se ve que no existe ninguna relación aparente entre las distribuciones de estas variables numéricas. Sin embargo, relaciones entre ellas o con otros atributos podrían tener incidencia en la variable de interés, por lo que no se van a obviar en primera instancia.

##### 2. EDA BIDEMSIONAL

Ahora se analizarán los efectos de las variables independientes de maner gráfica, con sólo una variable explicativa por plot. El análisis a continuación sólo se hará con las variables categóricas:

```{r}
#5. Boxplot Branch vs Rating
ggplot(df) +
  aes(x=Branch, y=Rating) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico


# OBS: Vemos que los precios son similares, pero que van subiendo un poco de Branch en Branch en cuando 
# la media. En cambio, en Rating, se ve una clara baja de este en la Branch B.

#6. Boxplot Day vs Rating
ggplot(df) +
  aes(x=Day, y=Rating) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico

#OBS: se ven ciertos cambios en el rating según el día

#9. Boxplot Semana vs Rating
ggplot(df) +
  aes(x=Semana, y=Rating) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico

#OBS: se ven ciertos cambios en el rating según la semana

#11. Boxplot Gender vs Rating
ggplot(df) +
  aes(x=Gender, y=Rating) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico

#OBS: no hay cambios notables

#13. Boxplot Payment vs Rating
ggplot(df) +
  aes(x=Payment, y=Rating) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico

#OBS: pocos cambios

#15. Boxplot Customer type vs Rating
ggplot(df) +
  aes(x=`Customer type`, y=Rating) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico

#17. Boxplot Customer type vs Rating
ggplot(df) +
  aes(x=`Customer type`, y=Rating) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico

```

Se puede observar que casi ninguna variable categórica parece tener un efecto por sí sola sobre la variable de inerés. Lo único destacable que podemos rescatar es la baja en el `Rating` que parece presentar la `Branch` B en primera instancia.

Ahora se realiza un último análisis con las variables numéricas:

```{r}

#17.1. Scatter Unir price vs Rating
ggplot(df) +
  aes(x=`Unit price`, y=Rating) +
  geom_point(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico

#17.2. Boxplot Quantity type vs Rating
ggplot(df) +
  aes(x=Quantity, y=Rating, group=Quantity) +
  geom_boxplot(alpha=0.4, fill="blue") #cambiamos el tipo de gráfico
```

Claramente se puede evidenciar que no existe relación alguna entre la variable de interés y el precio unitario por sí solo, ya que el scatterplot es prácticamente al azar. En cuanto a la cantidad de productos, tampoco se puede llegar a una conclusión, ya que no hay mayores cambios además de un leve aumento en las cantidades medias-altas, pero podría no ser un efecto.

Para corroborar completamente, se confirma por última vez con una matriz de correlaciones:

```{r}

df_numeric <- select_if(df, is.numeric)
corr <- cor(df_numeric)
corr

corr2 <- rcorr(as.matrix(df_numeric))
corr2

```

Nuevamente se ve que no existe relación alguna con las variables independientes numéricas de manera separada con respecto a la variable de interés. Las correlaciones son prácticamente 0 (y tampoco son significativas).

##### 3. EDA Tridimensional

A continuación, se analizarán efectos conjuntos (con más de una variable independiente) sobre la variable de interés, tomando distintas combinaciones de la base:

```{r}

#
# Tridimensionales Categóricas
#

#---------------------------------------------------------------------
# Branch v/s Rating

#18. Boxplot Branch v/s Rating r/ Gender
ggplot(df) +
  aes(x=Branch, y=Rating, col=Gender) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico
#OBS: hay variaciones entre calificaciones por genero según la tienda

#19. Boxplot Branch v/s Rating r/ `Customer type`
ggplot(df) +
  aes(x=Branch, y=Rating, col=`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico

#20. Boxplot Branch v/s Rating r/ `Product Line`
ggplot(df) +
  aes(x=Branch, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico
#OBS: hay variaciones entre las calificaciones según el tipo de producto y tienda

#21. Boxplot Branch v/s Rating r/ Payment
ggplot(df) +
  aes(x=Branch, y=Rating, col=Payment) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico
#OBS: hay ciertas variaciones pero no tan importantes

#---------------------------------------------------------------------
# Gender v/s Rating

#22. Boxplot Gender v/s Rating r/ `Customer type`
ggplot(df) +
  aes(x=Gender, y=Rating, col=`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico

#23. Boxplot Gender v/s Rating r/ `Product Line`
ggplot(df) +
  aes(x=Gender, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico

#24. Boxplot Gender v/s Rating r/ Payment
ggplot(df) +
  aes(x=Gender, y=Rating, col=Payment) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico

#---------------------------------------------------------------------
# `Customer type` v/s Rating

#25. Boxplot `Customer type` v/s Rating r/ `Product Line`
ggplot(df) +
  aes(x=`Customer type`, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico

#26. Boxplot `Customer type` v/s Rating r/ Payment
ggplot(df) +
  aes(x=`Customer type`, y=Rating, col=Payment) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico

#---------------------------------------------------------------------
# `Product Line` v/s Rating

#27. Boxplot `Product line`  v/s Rating r/ Payment
ggplot(df) +
  aes(x=Payment, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#---------------------------------------------------------------------

# Tiempo incluído

#---------------------------------------------------------------------

# Tiempo agregado

#28. Boxplot Branch v/s Rating r/ Day
ggplot(df) +
  aes(x=Day, y=Rating, col=Branch) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#29. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Week, y=Rating, col=Branch) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

# Tiempo contínuo 

#30. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Semana, y=Rating, col=Branch) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#31. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Month, y=Rating, col=Branch) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#---------------------------------------------------------------------

# Numéricas

#---------------------------------------------------------------------

#32. Scatterplot Unit Price v/s Rating r/ Gender
ggplot(df) +
  aes(x=`Unit price`, y=Rating, col=Gender)+ #Se agrega una dimensión de colores "col".
  geom_point(size=1, alpha=0.4) +
  geom_smooth(se=FALSE, method="lm") 

#33. Scatterplot Unit Price v/s Rating r/ Gender
ggplot(df) +
    aes(x=`Unit price`, y=Rating, col=`Product line`)+ #Se agrega una dimensión de colores "col".
    geom_point(size=1, alpha=0.4) +
  geom_smooth(se=FALSE, method="lm")

#33. Scatterplot Unit Price v/s Rating r/ Gender
ggplot(df) +
  aes(x=`Unit price`, y=Rating, col=Branch)+ #Se agrega una dimensión de colores "col".
  geom_point(size=1, alpha=0.4) +
  geom_smooth(se=FALSE, method="lm") 

```

De este análisis, ya se pueden observar ciertas interacciones entre variables que pudiesen explicar el Rating, como lo es en el caso del género y la línea de los productos, donde se puede ver que el género femenino presenta mayor variación de Rating entre líneas, mientras que el género masculino parace mantenerse constante entre ellas. En cuanto al tiempo, también se ven cambios en durante periodos, pero no podemos decir que haya efecto de momento.

##### 4. EDA Cuadrimensional

Similar a la parte anterior, se evlíua cómo afectan tres variables a Rating. Esto para ver efectos aún más complejos entre variables explicativas que afecten al Rating:

```{r}
#
# Cuadrimensional
#

#---------------------------------------------------------------------
# Branch:Gender v/s Rating

#35. Boxplot Branch:Gender v/s Rating r/ `Customer type`
ggplot(df) +
  aes(x=Branch:Gender, y=Rating, col=`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

#36. Boxplot Branch v/s Rating r/ `Product Line`
ggplot(df) +
  aes(x=Branch:Gender, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

#37. Boxplot Branch v/s Rating r/ Payment
ggplot(df) +
  aes(x=Branch:Gender, y=Rating, col=Payment) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))


# Branch:`Customer type` v/s Rating

#38. Boxplot Branch:`Customer type` v/s Rating r/ `Product Line`
ggplot(df) +
  aes(x=`Customer type`:Branch, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

#39. Boxplot Branch:`Customer type` v/s Rating r/ Payment
ggplot(df) +
  aes(x=Branch:`Customer type`, y=Rating, col=Payment) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

# Branch:Payment v/s Rating

#40. Boxplot Branch:Payment v/s Rating r/ `Product Line`
ggplot(df) +
  aes(x=Branch:Payment, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

#---------------------------------------------------------------------
# Gender:`Customer type` v/s Rating

#41. Boxplot Gender:`Customer type` v/s Rating r/ `Product line`
ggplot(df) +
  aes(x=Gender:`Customer type`, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

#42. Boxplot Gender:`Customer type` v/s Rating r/ Payment
ggplot(df) +
  aes(x=Payment:Gender, y=Rating, col=`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

# Gender:Payment v/s Rating

#43. Boxplot Gender:Payment v/s Rating r/ `Product line`
ggplot(df) +
  aes(x=Payment:Gender, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

#---------------------------------------------------------------------

# `Customer type`:Payment v/s Rating

#44. Boxplot `Customer type`:Payment v/s Rating r/ `Product line`
ggplot(df) +
  aes(x=`Customer type`:Payment, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))



#---------------------------------------------------------------------

# Tiempo incluído

#---------------------------------------------------------------------

# Tiempo agregado

#45. Boxplot Branch:`Customer type` v/s Rating r/ Day
ggplot(df) +
  aes(x=Day, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#46. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Week, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

# Tiempo contínuo 

#47. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Semana, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#48. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Month, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#---------------------------------------------------------------------

# Tiempo agregado

#49. Boxplot Branch:`Customer type` v/s Rating r/ Day
ggplot(df) +
  aes(x=Day, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#50. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Week, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

# Tiempo contínuo 

#51. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Semana, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

#52. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Month, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 


```

Se pueden ver efectos aún más notorios partiendo de los resultados interesantes anteriores. La combinación de variables Género/Pago/línea de producto parece tener mucha variación en el Rating, por lo que se tendrá presente en el resto del desarrollo.

En cuanto a otras, se puede destacar Branch/Tipo de cliente/ Porduct line también tiene bastante variabilidad en Rating.

#### Pregunta 2

(2.0 puntos) Usando los aprendizajes derivados de la exploración de datos, use un enfoque de regresión lineal para examinar cuantitativamente qué factores determinan la satisfacción al momento de realizar una compra.

**a)** Proponga al menos dos especificaciones alternativas para el objetivo propuesto. Justifique muy brevemente por que las variables que está incluyendo en el modelo tienen sentido desde el punto de vista del negocio. Justifique además el nivel de agregación escogido y los índices considerados en el modelo.

1\. En primera instancia se va a correr una regresión sólo con las variables que no guardan relación con el resto, tal cual vienen en la base. Esto es, no incluir dos varibles independientes tal que una se pueda explicar por la otra.

-   Customer type: se esperaría que haya cambios según se es miembro o no (ej. si es miembro puede ser más exigente a la hora de evaluar la tienda)

-   Gender: se esperaría un efecto según se es H/M (ej. cierto género es más exigente a la hora de evaluar)

-   Product line: podría haber cambios en el rating por la línea de producto

-   Unit price: se esperaría que mientras más caro un producto, menor rating

-   Quantity: a mayor cantidad, menor rating

-   Unit price\*Quantity: (Contiene información de Cogs), se esperaría que a mayor valor, menor rating

-   Month: dependiendo del mez, podría cambiar el rating (por ejemplo si es marzo)

-   Day: ciertos días podría variar el rating (ej. un lunes donde es comienzo de semana, podría bajar la nota dados los estados de ánimo)

-   Hour: ciertas horas del día, podrían variar el rating.

En cuanto al nivel de agregación, interesa ver cómo se ve afectado el Rating según fechas (mes, día, ...)

```{r P2_a reg1, warning=FALSE}
#Regresion lineal sin diferenciar por tienda

train.lm <- train(form = Rating ~ Branch + `Customer type` + Gender + `Product line` + `Unit price` +  Quantity + `Unit price`*Quantity + Payment + Month + Day + Hour, #Fórmula
                  data = train, #Datos
                  method = "lm", #Algoritmo 
                  trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold) 
)
test.lm  <- predict(train.lm , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.lm <- test$Rating-test.lm #Calcular los errores de predicción (dato real - dato estimado)
summary(train.lm)
print(paste('Error de predicción: ', mean(abs(error.lm))))
```

Se puede ver que la variable de interés no se explica muy bien por las variables independientes de este modelo, lo cual tiene sentido según el EDA bidimensional realizado en la parte anterior.

2\. Agregamos a la regresión la variable Week, donde podría haber un efecto al pasar el tiempo en semanas.

```{r p2_a reg2, warning=FALSE}

#2. Regresion lineal con intervalos temporales
train.lm2 <- train(form = Rating ~ Branch + `Customer type` + Gender + `Product line` + `Unit price` + Quantity + `Unit price`*Quantity + Payment + Month + Week + Day + Hour, #Fórmula
                  data = train, #Datos
                  method = "lm", #Algoritmo
                  na.action = na.pass, # Ignorar NA
                  trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold) 
)
test.lm2  <- predict(train.lm2 , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.lm2 <- test$Rating-test.lm2 #Calcular los errores de predicción (dato real - dato estimado)
summary(train.lm2)
print(paste('Error de predicción: ', mean(abs(error.lm2))))
```

Se puede observar que este modelo tampoco explica de la forma deseada la variable de interés (poca significancia), sin embargo, disminuye el error de predicción.

3\. Regresión con interacciones "Branch x Customer type x Month" y "Gender x Payment x Product line", pues se vio en el EDA cuadrimensional ciertas variaciones notables en la variable de interés. 

a. Branch x Customer type x Month: en el gráfico N°48 [ver anexo 1], se vieron variaciones según este tipo de variables, por ejemplo, según tienda, varía el Rating, lo mismo para tipo de cliente, y que estos efectos también varían según el mes.

b.  Gender x Payment x Product line: también se pueden ver variaciones interesantes en el gráfico N°43 [Ver anexo 2]

```{r P2_a reg3, warning=FALSE}

#3.Regresion lineal con intervalos temporales
train.lm3 <- train(form = Rating ~ 
                    Branch * `Customer type` * Month  + 
                    Gender  * Payment * `Product line` + 
                    `Unit price`+ Quantity + 
                    Hour + Day + Week, #Fórmula
                  data = train, #Datos
                  method = "lm", #Algoritmo
                  na.action = na.pass, # Ignorar NA
                  trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold) 
)
test.lm3  <- predict(train.lm3 , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.lm3 <- test$Rating-test.lm3 #Calcular los errores de predicción (dato real - dato estimado)
summary(train.lm3)
print(paste('Error de predicción: ', mean(abs(error.lm3))))
```

Disminuye el error de predicción, sin embargo, hay poca siginificancia en las variables.

4\. Separamos ahora la regresión por tiendas/branches, pues puede explicarse el rating según la tienda, teniendo efectos independientes. Además, se agrega las interacciones anteriores.

```{r p2_a reg4, warning=FALSE}

#4. Regresion lineal diferenciando por tienda 
allstores = unique(train$Branch) # Valores únicos de cada tienda

nobs = nrow(train)  # filas del set de training
nbranches = length(allstores) # n de tiendas

atributos_interes <- c('Total','Gender')
#regcoeff = array(NA, dim=c(nbranches,length(atributos_interes))) # matriz auxiliar vacía para los coefs de las 3 tiendas
regcoeff = array(NA, dim=c(nbranches,11))
# Loop en las tiendas
for (i in 1:nbranches){
 
  sub_train <- train[(train$Branch==allstores[i]),]

  
  
  #regrmodel = lm(Rating2 ~ Uprice + Gender2 + Semana2)
  reg_model <- lm(Rating ~
                     `Customer type` * Month  + 
                    Gender  * Payment * `Product line` + 
                    `Unit price`+ Quantity + 
                    Hour + Day + Week, #Fórmula, 
                  data = sub_train)
  
  #print(summary(reg_model))
 # print(reg_model$coeff)
  #regcoeff[i,] = reg_model$coeff
  
  sub_test <- test[test$Branch==allstores[i],]
  test.lm4  <- predict(reg_model , newdata=sub_test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
  error.lm4 <- (sub_test$Rating -  test.lm4) #Calcular los errores de predicción (dato real - dato estimado)
  summary(reg_model)
  print(paste('Branch:', allstores[i],'\tError:',mean(abs(error.lm4))))
}
```

Se puede observar distitnos errores de predicción según tienda.

**b)** Sobre los dos modelos planteados en la parte anterior, aplique un método de selección automática de variables y compare respecto a los resultados anteriores.

Para esta parte, se continuará trabajando con el modelo que mejor funcionó en las partes anteriores (menor error de predicción): 

Rating = Branch * Customer type * Month + Gender  * Payment * Product line + Hour + Day + Week + Unit price * Quantity

1.  Se usa LASSO para seleccionar las varibles más importantes de la regresión anterior, ya que va a castigar a los coeficientes que tengan mayor error llevando algunos a 0.

```{r P2_b lasso, warning=FALSE}
#Regresión autoselección
# Lasso

train.lasso <- train(form = Rating ~ 
                      Branch * `Customer type` * Month  +
                      Gender  * Payment * `Product line` +
                      Hour + Day + Week +
                     `Unit price`*Quantity, #Fórmula
                  data = train, #Datos
                  method = "glmnet", #Algoritmo 
                  tuneGrid = expand.grid(alpha = 1, lambda = 1),
                  trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold) 
)
test.lasso  <- predict(train.lasso , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.lasso <- test$Rating-test.lasso #Calcular los errores de predicción (dato real - dato estimado)

print(paste('Error de predicción: ', mae(train$Rating,test.lasso)))
```

Se observa una baja en el error de predicción, por lo que funciona la selección de variables.

2.  Se usa Regression Ridge para tener una segunda métrica de selección; sin embargo, esta en realidad no selecciona variables, si no que le baja la magnitud a variables que aporten menos a la disminución de error

```{r P2_b rr}
# Regresión NO-autoselección
# Ridge

train.rr <- train(form = Rating ~ 
                      Branch * `Customer type` * Month  +
                      Gender  * Payment * `Product line` +
                      Hour + Day + Week +
                      `Unit price`*Quantity, #Fórmula
                  data = train, #Datos
                  method = "glmnet", #Algoritmo 
                  tuneGrid = expand.grid(alpha = 0, lambda = 1),
                  trControl = trainControl(method = "cv", number = 5) #Method = cross validation, number=10 (k-fold) 
)
test.rr <- predict(train.rr , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.rr <- test$Rating-test.rr #Calcular los errores de predicción (dato real - dato estimado)

print(paste('Error de predicción: ', mae(train$Rating,test.rr)))
```

Aumenta el error de predicción en comparación a LASSO.

Dado lo anterior, LASSO pareciera ser el mejor método. Es decir, pareciera que eliminar variables innecesarias (o seleccionar las mejores) parece ser lo mejor, lo que tiene bastante sentido, ya que se incluyeron interacciones que podrían no aportar nada entre las combinaciones.

Como sólo se eleccionaron variables con LASSO, se necesita un segundo método de selección de variables para completar el análisis pedido. Usamos entonces la Stepwise Regression (Backward):

```{r p2_b step-back, warning=FALSE}

#Regresión autoselección
# stepwise backward

train.swb <- train(form = Rating ~ 
                      Branch * `Customer type` * Month  +
                      Gender  * Payment * `Product line` +
                      Hour + Day + Week +
                      `Unit price`*Quantity, #Fórmula
                  data = train, #Datos
                  method = "leapBackward", #Algoritmo 
                  tuneGrid = data.frame(nvmax = 1:15),
                  trControl = trainControl(method = "cv", number = 5)#Method = cross validation, number=10 (k-fold) 
)
test.swb <- predict(train.swb , newdata=test) #Vector de datos predichos. Recibe una base de datos (newdata) y un modelo entrenado (train.lm)
error.swb <- test$Rating-test.swb #Calcular los errores de predicción (dato real - dato estimado)

print(paste('Error de predicción: ', mae(train$Rating,test.swb)))
```

### Comparación de resultados

A continuación, se comparan los modelos anteriores (regresiones lineales y selección automática)

```{r p2_b comparacion}
rating.test <- data.frame(lm1=test.lm, lm2=test.lm2, lm3=test.lm3, lasso=test.lasso, ridge=test.rr, step.back=test.swb, rating=test$Rating)
error.test <- data.frame(lm1=error.lm, lm2=error.lm2, lm3=error.lm3, lasso=error.lasso, ridge=error.rr, step.back=error.swb)

summary(abs(error.test))
summary(error.test)
boxplot(abs(subset(error.test))); title(main="RL + Autom models", sub="Forecasting Absolute Errors")
boxplot(subset(error.test)); title(main="RL + Autom models", sub="Forecasting Errors")
```

#### Pregunta 3

(1.0 puntos) Use al menos dos de los modelos de aprendizaje de máquinas que vimos en clases (MARS, kNN, regression tree, random forest) para generar un pronóstico de Rating de un cliente al realizar una compra y compare la capacidad de estos modelos con respecto a los de regresión lineal.

Como KNN es un método que depende de una métrica de distancia (default euclidiana), entonces no se puede simplemente comparar los atributos numéricos con los categóricos, se necesita hacerlos comparables a ambos para que no dependa todo sólo de los numéricos. En este caso, se puede normalizar con el método de Min-Max:

```{r echo=FALSE}

# Min-Max:
min.max <- function(column){
  max <- max(column)
  min <- min(column)
  norm.column <- (column-min)/(max-min)  
  return(norm.column)
}

# Copia de train y test
train.knn <- data.frame(train)
test.knn  <- data.frame(test)

# Unit Price
train.knn$Unit.price <- min.max(train$`Unit price`)
test.knn$Unit.price  <- min.max(test$`Unit price`)

# Quantity
train.knn$Quantity <- min.max(train$Quantity)
test.knn$Quantity  <- min.max(test$Quantity)

# Rating
#train.knn$Rating <- min.max(train$Rating)
#test.knn$Rating  <- min.max(test$Rating)

head(train.knn)
```

##### 1. KNN

```{r P3 knn, warning=FALSE}
#Modelo de aprendizaje de máquinas
#1. ML --> KNN
train.knn.prediction<- train(Rating ~ 
                      Branch * Customer.type* Month  +
                      Gender  * Payment * Product.line +
                      Hour + Day + Week + 
                      Unit.price*Quantity, #Fórmula
                   data=train.knn, 
                   method="knn",  
                   trControl = trainControl("cv", number=10),
                   preProcess = c("center","scale"),
                   tuneLength = 10
)

print(train.knn.prediction)
ggplot(train.knn.prediction)
test.knn.prediction  <- predict(train.knn.prediction, newdata=test.knn) 
error.knn <- test.knn$Rating-test.knn.prediction
print(paste('Error de predicción: ', mae(train$Rating,test.knn.prediction)))
```

##### 2. Random Forest

```{r P3 rf, warning=FALSE}

#2. ML --> Random forest
train.randomf <- train(Rating ~ 
                        Branch * `Customer type` * Month  +
                        Gender  * Payment * `Product line` +
                        Hour + Day + Week +
                        `Unit price`*Quantity, #Fórmula
                       data=train, method="rf",  
                       trControl = trainControl("cv", number=5),
                       preProcess = c("center","scale"),
                       tuneLength = 5 
)
print(train.randomf)
ggplot(train.randomf)
test.randomf  <- predict(train.randomf, newdata=test) 
error.randomf <- test$Rating-test.randomf
print(paste('Error de predicción: ', mae(train$Rating,test.randomf)))
```

#### Pregunta 4

(0.5 puntos) Compare las fortalezas y debilidades de los modelos anteriores, evalúe de acuerdo a algunas de las métricas que vimos en clases y discuta qué modelo recomendaría usar.

Para comparar, se utilizaran las métricas RMSE y MAE. Los resultados se resumen en la siguiente tabla:

```{r P4}
#Comparación modelos y recomendación

Metricas=data.frame(Modelo=c("lm1","lm2","lm3","LASSO","Ridge","Stepwise (backward)", "KNN","Random Forest"), RMSE=NA, MAE=NA)


#RMSE
Metricas[1,2] = rmse(train$Rating,test.lm) #lm1
Metricas[2,2] = rmse(train$Rating,test.lm2) #lm2
Metricas[3,2] = rmse(train$Rating,test.lm3) #lm3
Metricas[4,2] = rmse(train$Rating,test.lasso) #lasso
Metricas[5,2] = rmse(train$Rating,test.rr) #ridge
Metricas[6,2] = rmse(train$Rating,test.swb) #swb
Metricas[7,2] = rmse(train.knn$Rating,test.knn.prediction)#knn
Metricas[8,2] = rmse(train$Rating,test.randomf) #rf


#MAPE 
Metricas[1,3] = mae(train$Rating,test.lm) #lm1
Metricas[2,3] = mae(train$Rating,test.lm2) #lm2
Metricas[3,3] = mae(train$Rating,test.lm3) #lm3
Metricas[4,3] = mae(train$Rating,test.lasso) #lasso
Metricas[5,3] = mae(train$Rating,test.rr) #ridge
Metricas[6,2] = mae(train$Rating,test.swb) #swb
Metricas[7,2] = mae(train.knn$Rating,test.knn.prediction)#knn
Metricas[8,2] = mae(train$Rating,test.randomf) #rf


kable(Metricas)

# Dataframe para Boxplots

rating.test <- data.frame(lm1=test.lm, lm2=test.lm2, lm3=test.lm3, lasso=test.lasso, ridge=test.rr, step.back=test.swb, knn=test.knn.prediction, rf=test.randomf, rating=test$Rating)
error.test <- data.frame(lm1=error.lm, lm2=error.lm2, lm3=error.lm3, lasso=error.lasso, ridge=error.rr, step.back=error.swb, knn=error.knn, rf=error.randomf)

boxplot(abs(subset(error.test))); title(main="RL + Autom models", sub="Forecasting Absolute Errors")
boxplot(subset(error.test)); title(main="RL + Autom models", sub="Forecasting Errors")
```


En cuanto a las fortalezas y debilidades de cada modelo, se tiene que para los de regresión lineal, si bien son los únicos que permiten obtener inferencia estadística, hay que probar varios modelos hasta encontrar uno óptimo, lo cual en este caso no resultaría eficiente pues se vio que lo que explica el modelos son interacciones entre variables, por lo que habría que indagar e invertir bastante tiempo.

Por otro lado, los modelos de Machine Learning, si bien toman un conjunto de datos y los trabajan para realizar una predicción óptima, en este caso no resultaron mejor que los de selección automática. Esto se puede deber a la cantidad de datos con los que se trabajó (que si fuesen más, los métodos de ML podrían funcionar mejor).En particular, para el caso de Knn es un algoritmo sencillo que se basa escencialmente en la distancia entre observaciones. Algunas desventajas radican en que hay que ajustar los datos para que las distancias sean comparables y que no entrega información de cómo se relacionan las variables, siendo un modelo principalmente enfocado en la predicción. Para el caso de Random Forest también se tiene un modelo sencillo, donde no se necesita ajustar los datos, pues se basa en un sampleo aleatorio de árboles de decisión. Un problema de Random Forest radica en el tiempo computacional que implica el sampleo aleatorio de estos árboles.

Por último, se puede observar que aquellos modelos que mejor funcionan son el de selección automática LASSO y Stepwise Regression (backwards), entregando menor error y variación. Esto se puede deber a que fueron seleccionando aquellas variables e interacciones funcionaban mejor para explicar la variable de interés Rating. Así, se recomendaría utilizar estos. Sin embargo, para hacer inferencia estadística, los de regresión lineal resultan más útil.



#### Pregunta 5

(2.0 puntos) En esta parte, se compararán los grados de satisfacción entre las distintas salas de la cadena de supermercados. Para lo siguiente usted deberá clasificar cada evaluación de la calidad de servicios de acuerdo a si el cliente está o no satisfecho. Para eso puede considerar que un cliente está satisfecho si tiene un Rating mayor o igual a los 7 puntos. Con esto:

**a)**Estimar un modelo de decisión homogéneo para cada sucursal y compare sus resultados entre sucursales. Discuta brevemente sus resultados.

Esta sección se encuentra en el HTML a partir del desrrollo en Python/Jupyter Notebook, por lo que se debe seguir el desarrollo desde allá.

**b)**Estimar un modelo de decisión heterogéneo para cada sucursal y compare sus resultados entre sucursales. Discuta brevemente sus resultados.

Esta sección se encuentra en el HTML a partir del desrrollo en Python/Jupyter Notebook, por lo que se debe seguir el desarrollo desde allá.

## Resumen y Conclusiones

Documenta acá el resumen y las conclusiones principales (esto te servirá para la presentación del jueves 6)

#### Pregunta 6


Finalmente, dado el estudio de modelos desarrollado, se puede concluir, primero, que las variables por sí solas pueden no explicar fenómenos complejos como la decisión de qué nivel de satisfacción se tiene con una atención, pues distintos factores pueden afectar en conjunto. Esto se vio en el EDA inicial y también en las primeras regresiones lineales donde se evluaba cómo una variable independiente podía explicar el Rating, sin embargo, se vio poca significancia y correlación.

En segundo lugar, se vio que los métodos de selección automática tuvieron un rendimiento mejor, lo cual puede deberser a fenómenos que no se pueden ver a simple vista, y que guardan relación con cada posible varibale e interacción.

Tercero, existen otros modelos que pueden funcionar de manera más óptima que una regresión lineal para explicar fenómenos complejos. Lo anterior se vio comparando los errores de predicción de los modelos de regresión lineal, selección automática y machine learning, donde para el caso de LASSO y Stepwise Regresion (backward), entregaba un mejor resultado. Sin embargo, la regresión lineal es el único modelo con el que se puede hacer inferencia estadística.

Por otro lado, para un caso de estudio futuro, sería mejor comprender más a fondo cada uno de los modelos con los que se trabajó para de esta manera, discernir en qué situación ocupar cada uno y cómo tratar los datos tal que se adapte mejor al modelos escogido y obtener mejores resultados.

También se puede concluir que si bien nada predice con un 100% de precisión, una mejora de, por ejemplo, un 1%, puede significar un beneficio para la cadena de supermercados. Esto es, dentro de todos los modelos estudiados, elegir aquel que tuvo mejor rendimiento y que pueda mejorar los resultados de la marca.

Por último, en cuanto a los modelos de decisión (homogeneo y heterogeneo), se observa que las distribuciones sobre los $\theta$ correspondientes a cada Branch dependen bastante poco de la segmentación, al tener parámetros $\alpha$ y $\beta$ muy altos. En general se ve que hay poca certeza a la hora de ver si un cliente está satisfecho, donde la probabilidad en los modelos estudiados siempre se estima cercana a 0.5. Esto daría a entender que es muy difícil hacer inferencias sobre el comportamiento de los distintos clientes, pero si se pueden hacer inferencias del comportamiento agregado de los clientes y segmentos, donde se espera que la fracción de clientes satisfechos esté cercano al 50%.


\begin{table}[]
\begin{tabular}{llll}
         & $\alpha$ & $\beta$  & $E(\theta)$ \\ \hline
Branch A & 568.640  & 485.328  & 0.54        \\
Branch B & 519.556  & 530.852  & 0.495       \\
Branch C & 581.162  & 473.7344 & 0.55       
\end{tabular}
\end{table}

 

## Anexos

Documenta acá cualquier otro adicional que consideres útil tener de referencia.

#### Pregunta 2

```{r PX}

#48. Boxplot Branch v/s Rating r/ Week
ggplot(df) +
  aes(x=Month, y=Rating, col=Branch:`Customer type`) +
  geom_boxplot(alpha=0.4, fill='white') #cambiamos el tipo de gráfico 

```

#### Pregunta 2

```{r PY}
#43. Boxplot Gender:Payment v/s Rating r/ `Product line`
ggplot(df) +
  aes(x=Payment:Gender, y=Rating, col=`Product line`) +
  geom_boxplot(alpha=0.4, fill='white') + #cambiamos el tipo de gráfico
  theme(axis.text.x = element_text(angle = 30))

```


