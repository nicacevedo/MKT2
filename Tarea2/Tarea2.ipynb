{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tarea 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Un canal televisivo ha observado desde las sombras cómo el Animé ha aumentado su popularidad de manera exponencial durante el último tiempo, por lo que se dispone a realizar su próxima apuesta por la animación japonesa y busca elegir qué serie comenzar a emitir. Para ello esta auspiciando el famoso festival “OtakuFest” lugar al que asisten tanto fans de la cultura japonesa, como los denominados Expertos, personas capaces de pasar más de 24 horas seguidas frente a una pantalla a disfrutar de una serie acompañados de su infaltable dosis de maruchan. Los Expertos han estado observando 4 tipos distintos de anime durante el último tiempo: 1.Hunter x Hunter, 2.Dragon Ball, 3.Naruto y 4.My Hero Academia. En el final del evento, los expertos votaron para escoger al animé de su preferencia dentro de las elecciones para decidir el ganador , el cual será finalmente transmitido en el canal televisivo.\n",
    "\n",
    "Los resultados de la votación están incluidos en la base de datos “Anime.csv”, la cual posee una estructura de panel, en la cual cada fila representa un capítulo de la serie correspondiente, con sus respectivas características. La variable “Elección” toma el valor 1 si es que el Experto votó por dicho capítulo y 0 si no. El experto debe realizar su votación comparando el n-ésimo capítulo de cada serie y elegir de entre los cuatro cuál es el que más le gustó. Por ejemplo, luego de ver el primer capítulo de cada uno de los 4 anime, el experto elige un sólo ganador de los 4. Para no sobre-cargar cognitivamente a los Expertos, la evaluación selimitó a la evaluación de los primeros 12 capitulos de cada serie.\n",
    "\n",
    "El equipo de programación piensa que esta información puede ser muy relevante para guiar las decisiones de programación. En estas decisión es importante considerar no solo cuál es la serie que tiene mayor rating sino que también el público al que les resulta más atractivo y si hubieran dinámicas en la evaluación en el tiempo. Quizás hay algunas series que, aunque en el global pueden ser bien evaluadas, podrían una partida lenta con baja preferencia en los primeros capítulos. Aunque hay un amplio historial de series existosas que han partido con bajo rating, es útil indentificar estas dinámicas para que, en caso de emitirse, el lanzamiento sea apoyado con estrategias promocionales que consoliden la propuesta de valor.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Preguntas\n",
    "\n",
    "1. (0 puntos) Explore los datos para poder entender qué variables podrían ser más influyentes en el hecho de que un experto elija un anime.\n",
    "\n",
    "2. (2,0 puntos) Defina un modelo Logit y Mixed Logit multinomiales para estudiar las razones que llevan a un experto a elegir animes. Interprete los coeficientes y calcule la probabilidad de que una mujer de 25 años elija el anime naruto para el modelo logit multinomial.\n",
    "\n",
    "3. (1,0 puntos) Construya un modelo Probit que capture los elementos de elección principales y comente sobre cómo se interpretan sus coeficientes.\n",
    "\n",
    "4. (2,0 puntos) Utilizando lo aprendido de los modelos anteriores, construya dos modelos de machine and learning diferentes y compárelos con los modelos logits y probits estimados anteriormente, para ello calcule la matriz de confusión de cada modelo respecto a su predicción y utilice métricas derivadas a partir de esta para la comparación de los modelos.\n",
    "\n",
    "5. (1,0 puntos) Resuma sus aprendizajes principales en un máximo de 4 tablas o figuras. Redacte de manera concisa sus resultados tal como los reportaría al departamento comercial interesado en informarse de la preferencia de los expertos. Agregue cualquier conclusión o idea que le parezca relevante de comunicar para que los representantes del canal de televisión tomen la mejor estrategia de programación televisiva.\n",
    "\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Escribe acá todos los comandos que necesitas ejecutar antes de abordar las preguntas de la tarea (carga de librerías, lectura de datos, limpieza de la data, transformación de variables y todo lo que necesites)\n",
    "\n",
    "#### Preparación Tarea"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Expertos  Capitulos  ...  DuracionCapituloMin  RatingTV\n",
       "306.1.1       306          1  ...                   37         5\n",
       "203.5.4       203          5  ...                   55        16\n",
       "437.2.1       437          2  ...                   50        30\n",
       "918.2.1       918          2  ...                   50        30\n",
       "546.6.1       546          6  ...                   34        22\n",
       "\n",
       "[5 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Expertos</th>\n      <th>Capitulos</th>\n      <th>Animes</th>\n      <th>Edad</th>\n      <th>Mujer</th>\n      <th>CantCaps</th>\n      <th>Scoremyanimelist</th>\n      <th>NEscenasCombate</th>\n      <th>NescenasEmocionantes</th>\n      <th>CalidadAnimacion</th>\n      <th>DuracionCapituloMin</th>\n      <th>RatingTV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>306.1.1</th>\n      <td>306</td>\n      <td>1</td>\n      <td>1</td>\n      <td>29</td>\n      <td>1</td>\n      <td>575</td>\n      <td>8.15</td>\n      <td>1</td>\n      <td>6</td>\n      <td>7</td>\n      <td>37</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>203.5.4</th>\n      <td>203</td>\n      <td>5</td>\n      <td>4</td>\n      <td>37</td>\n      <td>1</td>\n      <td>113</td>\n      <td>8.04</td>\n      <td>12</td>\n      <td>2</td>\n      <td>7</td>\n      <td>55</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>437.2.1</th>\n      <td>437</td>\n      <td>2</td>\n      <td>1</td>\n      <td>46</td>\n      <td>1</td>\n      <td>575</td>\n      <td>8.15</td>\n      <td>8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>50</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>918.2.1</th>\n      <td>918</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n      <td>0</td>\n      <td>575</td>\n      <td>8.15</td>\n      <td>8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>50</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>546.6.1</th>\n      <td>546</td>\n      <td>6</td>\n      <td>1</td>\n      <td>42</td>\n      <td>0</td>\n      <td>575</td>\n      <td>8.15</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>34</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Librerías de ML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset\n",
    "df = pd.read_csv('./Dataset/Anime.csv', index_col=0)\n",
    "df.head(10)\n",
    "\n",
    "# X e y\n",
    "X = df.drop('Eleccion', axis=1)\n",
    "y = df['Eleccion']\n",
    "\n",
    "# Separamos el dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123) # 33% test\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/nicacevedo/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Reg Logística\n",
    "logit = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = logit.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.18352272727272728"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "rmse = ((y_pred - y_test)**2).mean()\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([8.15])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": []
  }
 ]
}